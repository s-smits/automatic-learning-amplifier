[{"question": "What is the Kolmogorov-Arnold representation theorem?", "answer": "The Kolmogorov-Arnold representation theorem is a theorem that states that a multivariate continuous function can be written as a finite composition of continuous functions of a single variable and the binary operation of addition."}, {"question": "What is a Kolmogorov-Arnold network (KAN)?", "answer": "A Kolmogorov-Arnold network (KAN) is a type of neural network inspired by the Kolmogorov-Arnold representation theorem, which replaces traditional activation functions with learnable activation functions on edges."}, {"question": "What are B-spline curves?", "answer": "B-spline curves are a type of curve that can be used to parametrize univariate functions."}, {"question": "How do KANs differ from traditional neural networks?", "answer": "KANs treat linear transformations and nonlinearities together in \u03a6, whereas traditional neural networks treat them separately as W and \u03c3."}, {"question": "What are the key tricks to make KAN layers well-optimizable?", "answer": "The key tricks are: (1) Residual activation functions, (2) Initialization scales, and (3) Update of spline grids."}]