[{"question": "What is the Kolmogorov-Arnold representation theorem?", "answer": "The Kolmogorov-Arnold representation theorem is a theorem that states that a multivariate continuous function can be written as a finite composition of continuous functions of a single variable and the binary operation of addition."}, {"question": "What are Kolmogorov-Arnold networks (KANs)?", "answer": "Kolmogorov-Arnold networks (KANs) are a type of neural network inspired by the Kolmogorov-Arnold representation theorem, which replaces traditional activation functions with learnable activation functions on edges."}, {"question": "How do B-spline curves parametrize univariate functions?", "answer": "B-spline curves can be used to parametrize univariate functions by representing each 1D function as a B-spline curve, with learnable coefficients of local B-spline basis functions."}, {"question": "How do you make KANs deeper?", "answer": "To make KANs deeper, you can stack more KAN layers, similar to how multi-layer perceptrons (MLPs) are built by stacking more layers."}, {"question": "What is a KAN layer?", "answer": "A KAN layer is a matrix of 1D functions, where the functions have trainable parameters, and can be defined as a matrix of 1D functions \u03a6={\u03d5q,p}, p = 1,2,\u00b7\u00b7\u00b7, nin, q = 1,2\u00b7\u00b7\u00b7, nout."}]