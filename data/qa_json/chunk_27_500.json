[{"question": "What are the limitations of traditional neural networks?", "answer": "Traditional neural networks are limited in expressive power and many of them are even predating back-propagation. Therefore, most studies were built on theories with rather limited or artificial toy experiments."}, {"question": "What is the contribution of this paper?", "answer": "The contribution of this paper lies in generalizing the network to arbitrary widths and depths, revitalizing and contextualizing them in today's deep learning stream, as well as highlighting its potential role as a foundation model for AI Neural Scaling Laws (NSLs)."}, {"question": "What are Neural Scaling Laws (NSLs)?", "answer": "NSLs are the phenomena where test losses behave as power laws against model size, data, compute, etc. The origin of NSLs still remains mysterious, but competitive theories include intrinsic dimensionality, quantization of tasks, resource theory, random features, compositional sparsity, and maximum arity."}, {"question": "What is the significance of Kolmogorov-Arnold representation in neural networks?", "answer": "A high-dimensional function can surprisingly scale as a 1D function if it has a smooth Kolmogorov-Arnold representation. This promises the fastest scaling exponent ever, bringing fresh optimism to neural scaling laws."}, {"question": "What is Mechanistic Interpretability (MI) and how does it relate to this paper?", "answer": "MI is an emerging field that aims to mechanistically understand the inner workings of neural networks. Our work lies in the second category, where the model and training method are by design interpretable, focusing on learnable activations and symbolic regression."}]